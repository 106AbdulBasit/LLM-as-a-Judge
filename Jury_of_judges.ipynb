{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "68JipEvJ3d1X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltZLwFQ7ipKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\" Prompt:  Instruction-Following\n",
        "You are an advanced text processing agent. Follow each of the 15 instructions below exactly and in order. Apply them to the provided paragraph. Be precise, strict with conditions, and make no omissions or assumptions beyond the rules.\n",
        "\n",
        "üîß Instructions:\n",
        "Replace all acronyms with their full forms (e.g., AI ‚Üí Artificial Intelligence).\n",
        "\n",
        "\n",
        "Remove any sentence that contains more than two numerical digits.\n",
        "\n",
        "\n",
        "Capitalize the first word of every sentence.\n",
        "\n",
        "\n",
        "Do not alter the third sentence in the original paragraph.\n",
        "\n",
        "\n",
        "Change passive voice to active voice in even-numbered sentences only.\n",
        "\n",
        "\n",
        "Remove any sentence that starts with \"However\" or \"Although.\"\n",
        "\n",
        "\n",
        "If a sentence includes a city name, replace it with \"[REDACTED]\".\n",
        "\n",
        "\n",
        "In any sentence containing the word ‚Äúdata,‚Äù add the word ‚Äúsensitive‚Äù before ‚Äúdata.‚Äù\n",
        "\n",
        "\n",
        "Highlight all proper nouns by surrounding them with ** (e.g., Google).\n",
        "\n",
        "\n",
        "If a sentence is longer than 20 words, split it into two sentences.\n",
        "\n",
        "\n",
        "Merge any two consecutive sentences that are both under 8 words.\n",
        "\n",
        "\n",
        "Leave the final sentence unchanged, even if other rules apply.\n",
        "\n",
        "\n",
        "Keep only the first and last paragraph; delete all others.\n",
        "\n",
        "\n",
        "Add a summary line at the beginning: ‚Äú Edited for clarity and compliance.‚Äù\n",
        "\n",
        "\n",
        "Return the final output as plain text with line breaks between paragraphs.\n",
        "\n",
        "\n",
        "In 2023, researchers at MIT developed an AI-driven tool to streamline logistics in urban environments like New York and Tokyo. The tool uses IoT sensors to collect data from thousands of delivery trucks, ensuring real-time visibility into routes.\n",
        "Although the technology was in development for over two years, it gained commercial traction only after successful trials in Berlin. It was said that the system was designed to be scalable and efficient. However, analysts at Stanford warned of data privacy concerns.\n",
        "The software was later integrated with ERP systems by a team based in Lahore. This allowed seamless automation across multiple distribution hubs. One key feature involved predictive maintenance, powered by machine learning and natural language processing models.\n",
        "These models were trained on over 250,000 historical delivery records, offering unparalleled insights. Meanwhile, the company‚Äôs R&D division in Toronto continued improving model accuracy. Despite setbacks, the project demonstrated remarkable efficiency gains. The final release was announced at the Smart Cities Expo in Dubai.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xE50QtTKipPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import re"
      ],
      "metadata": {
        "id": "FRU_c7lal1bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the data set\n",
        "laod the phi model\n",
        "define the functions\n",
        "one for judjde the outputs\n",
        "one in which this function will be called\n"
      ],
      "metadata": {
        "id": "8z26zj-mllYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict\n",
        "\n",
        "import openai\n",
        "import re\n",
        "from typing import List\n",
        "import json\n",
        "\n",
        "from openai import OpenAI\n",
        "import anthropic"
      ],
      "metadata": {
        "id": "e7C6j-2ptGqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys\n",
        "openai.api_key = \"You open api key\"  # ‚ö†Ô∏è Replace with your actual key"
      ],
      "metadata": {
        "id": "ODQO2mV6r6tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-your claude key\""
      ],
      "metadata": {
        "id": "ivkktabQNdHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAI(api_key=openai.api_key)\n",
        "client = anthropic.Anthropic(api_key=claude_key)"
      ],
      "metadata": {
        "id": "TJVSBFTHA5s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRb85LkLNbRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def openai_judge_score(instructions: List[str], original_paragraph: str, completion: str) -> int:\n",
        "    system_prompt = (\n",
        "        \"You are an expert evaluator of instruction-following in text editing tasks. \"\n",
        "        \"You will be given a set of editing instructions, the original paragraph, and a modified paragraph. \"\n",
        "        \"You must return ONLY the number of instructions that were followed exactly. \"\n",
        "        \"Do not explain or justify. Just return a single number (0 to N).\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Instructions:\n",
        "{chr(10).join(f\"{i+1}. {instr}\" for i, instr in enumerate(instructions))}\n",
        "\n",
        "Original Paragraph:\n",
        "{original_paragraph}\n",
        "\n",
        "Edited Output:\n",
        "{completion}\n",
        "\n",
        "How many of the above {len(instructions)} instructions were followed exactly?\n",
        "Return just the number, nothing else.\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0\n",
        "        )\n",
        "        reply = response.choices[0].message.content.strip()\n",
        "        match = re.search(r'\\d+', reply)\n",
        "        if match:\n",
        "            value = int(match.group(0))\n",
        "            return max(0, min(value, len(instructions)))\n",
        "        else:\n",
        "            print(f\"[OpenAI] Unexpected format: {reply}\")\n",
        "            return 0\n",
        "    except Exception as e:\n",
        "        print(f\"[OpenAI] Error: {e}\")\n",
        "        return 0"
      ],
      "metadata": {
        "id": "9s7JxtFFrp2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eNc_gxbgGsVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Judge of Gemini**"
      ],
      "metadata": {
        "id": "oxZImh2zFpjB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1ek6FDzRWpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRRxtzjJSSoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Claude Judge **"
      ],
      "metadata": {
        "id": "R8DOVU_HGttW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def claude_judge_score(instructions: List[str], original_paragraph: str, completion: str) -> int:\n",
        "    \"\"\"\n",
        "    Evaluates instruction-following in text editing tasks using Claude.\n",
        "\n",
        "    Args:\n",
        "        instructions: List of editing instructions to evaluate\n",
        "        original_paragraph: The original text before editing\n",
        "        completion: The edited text to evaluate\n",
        "\n",
        "    Returns:\n",
        "        Number of instructions followed exactly (0 to len(instructions))\n",
        "    \"\"\"\n",
        "    client = anthropic.Anthropic()  # Initialize client inside function\n",
        "    system_prompt = (\n",
        "        \"You are an expert evaluator of instruction-following in text editing tasks. \"\n",
        "        \"You will be given a set of editing instructions, the original paragraph, and a modified paragraph. \"\n",
        "        \"You must return ONLY the number of instructions that were followed exactly. \"\n",
        "        \"Do not explain or justify. Just return a single number (0 to N).\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Instructions:\n",
        "{chr(10).join(f\"{i+1}. {instr}\" for i, instr in enumerate(instructions))}\n",
        "\n",
        "Original Paragraph:\n",
        "{original_paragraph}\n",
        "\n",
        "Edited Output:\n",
        "{completion}\n",
        "\n",
        "How many of the above {len(instructions)} instructions were followed exactly?\n",
        "Return just the number, nothing else.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=\"claude-3-5-sonnet-20240620\",  # Current Claude Sonnet 4\n",
        "            max_tokens=50,\n",
        "            temperature=0,\n",
        "            system=system_prompt,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        reply = response.content[0].text.strip()\n",
        "        match = re.search(r'\\d+', reply)\n",
        "        if match:\n",
        "            value = int(match.group(0))\n",
        "            return max(0, min(value, len(instructions)))\n",
        "        else:\n",
        "            print(f\"[Claude] Unexpected format: {reply}\")\n",
        "            return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Claude] Error: {e}\")\n",
        "        return 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_G60oRfiCs1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jurry of jduges**"
      ],
      "metadata": {
        "id": "tP5n2h5BaNMy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwqBoWEwaQLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hi3N2Bk0Cs2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to extract the parapgah and  instructions\n",
        "def extract_instructions_and_paragraph(prompt: str) -> tuple[list[str], str]:\n",
        "    start_marker = \"Instructions:\"\n",
        "    end_marker = \"Return the final output as plain text with line breaks between paragraphs.\"\n",
        "\n",
        "    if start_marker in prompt and end_marker in prompt:\n",
        "        # Find start and end positions\n",
        "        start_index = prompt.index(start_marker) + len(start_marker)\n",
        "        end_index = prompt.index(end_marker) + len(end_marker)\n",
        "\n",
        "        # Extract instruction block (excluding the \"Instructions:\" line itself)\n",
        "        instructions_block = prompt[start_index:prompt.index(end_marker)].strip()\n",
        "\n",
        "        # Split instructions into list by lines and remove empty ones\n",
        "        instructions_list = [line.strip() for line in instructions_block.splitlines() if line.strip()]\n",
        "\n",
        "        # Extract paragraph after end marker\n",
        "        paragraph = prompt[end_index:].strip()\n",
        "\n",
        "        if not instructions_list:\n",
        "            raise ValueError(\"No instructions found between markers.\")\n",
        "        if not paragraph:\n",
        "            raise ValueError(\"No paragraph found after the instructions block.\")\n",
        "\n",
        "        return instructions_list, paragraph\n",
        "\n",
        "    raise ValueError(\"Start or end marker not found in prompt.\")"
      ],
      "metadata": {
        "id": "s15GGzn3oHn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to split the instructions into different\n",
        "def chunk_instructions(instructions: List[str], n_parts: int = 2) -> List[List[str]]:\n",
        "    total = len(instructions)\n",
        "    base_size = total // n_parts\n",
        "    remainder = total % n_parts\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    for i in range(n_parts):\n",
        "        # First 'remainder' chunks get one extra item\n",
        "        chunk_size = base_size + (1 if i < remainder else 0)\n",
        "        end = start + chunk_size\n",
        "        chunks.append(instructions[start:end])\n",
        "        start = end\n",
        "\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "MMKd5xqhoFRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JsDER22AaK5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "def score(prompts: List[str], completions: List[str], models: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Scores prompt-completion pairs using a jury of judges (OpenAI, Claude, Gemini).\n",
        "    Computes (followed / total) per judge, then averages across judges.\n",
        "\n",
        "    Args:\n",
        "        prompts: List of full prompts (including instructions + paragraph)\n",
        "        completions: List of completions corresponding to the prompts\n",
        "        models: List of model identifiers for each completion\n",
        "\n",
        "    Returns:\n",
        "        Dictionary: model_id ‚Üí average compliance score (0.0 to 1.0)\n",
        "    \"\"\"\n",
        "    assert len(prompts) == len(completions) == len(models), \"Input lists must be equal length\"\n",
        "\n",
        "    model_scores = defaultdict(list)\n",
        "\n",
        "    # Extract shared instructions & paragraph\n",
        "    full_instructions, shared_paragraph = extract_instructions_and_paragraph(prompts[0])\n",
        "    instruction_chunks = chunk_instructions(full_instructions, n_parts=2)\n",
        "\n",
        "    total_instructions = len(full_instructions)  # Used for normalization\n",
        "\n",
        "    for prompt, completion, model_id in zip(prompts, completions, models):\n",
        "\n",
        "        # Call each judge separately and accumulate their total \"followed\"\n",
        "        followed_counts = []\n",
        "\n",
        "        for judge_fn in [openai_judge_score, claude_judge_score]:\n",
        "            followed = 0\n",
        "            for chunk in instruction_chunks:\n",
        "                followed += judge_fn(chunk, shared_paragraph, completion)\n",
        "            score = followed / total_instructions\n",
        "            followed_counts.append(score)\n",
        "\n",
        "        # Average across judges\n",
        "        final_score = sum(followed_counts) / len(followed_counts)\n",
        "        model_scores[model_id].append(final_score)\n",
        "\n",
        "    # Average the compliance scores per model\n",
        "    avg_scores = {\n",
        "        model_id: sum(scores) / len(scores)\n",
        "        for model_id, scores in model_scores.items()\n",
        "    }\n",
        "\n",
        "    return avg_scores"
      ],
      "metadata": {
        "id": "dZ2Ptgbtn8dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSvlsBHwifRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Phase**"
      ],
      "metadata": {
        "id": "7njIEaFRIZA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the dataset"
      ],
      "metadata": {
        "id": "s9WPbNlAxhfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import List\n",
        "def read_prompt_as_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "\n",
        "     return f.read()\n",
        "\n"
      ],
      "metadata": {
        "id": "F4w6r4TD0dD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def load_completions(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    completions = re.findall(r\"Completion \\d+:\\s*(.*?)\\s*(?=Completion \\d+:|$)\", text, re.DOTALL)\n",
        "    return [c.strip() for c in completions]\n",
        "\n",
        "def load_models(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        models = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    return models\n"
      ],
      "metadata": {
        "id": "vC-0eLDIhUu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = read_prompt_as_text(\"/content/Prompts.txt\")\n",
        "completions = load_completions(\"/content/Completions.txt\")\n",
        "model_ids = load_models(\"/content/Models.txt\")"
      ],
      "metadata": {
        "id": "F_9QpyjEuvoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [prompt] * 3"
      ],
      "metadata": {
        "id": "T-cFwBXxuvrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "3WIF-UM-2Fpb",
        "outputId": "1bcc435f-d21a-4659-ab77-bdbf4953ec19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prompt:  Instruction-Following \\nYou are an advanced text processing agent. Follow each of the 15 instructions below exactly and in order. Apply them to the provided paragraph. Be precise, strict with conditions, and make no omissions or assumptions beyond the rules.\\n\\nüîß Instructions:\\nReplace all acronyms with their full forms (e.g., AI ‚Üí Artificial Intelligence).\\n\\n\\nRemove any sentence that contains more than two numerical digits.\\n\\n\\nCapitalize the first word of every sentence.\\n\\n\\nDo not alter the third sentence in the original paragraph.\\n\\n\\nChange passive voice to active voice in even-numbered sentences only.\\n\\n\\nRemove any sentence that starts with \"However\" or \"Although.\"\\n\\n\\nIf a sentence includes a city name, replace it with \"[REDACTED]\".\\n\\n\\nIn any sentence containing the word ‚Äúdata,‚Äù add the word ‚Äúsensitive‚Äù before ‚Äúdata.‚Äù\\n\\n\\nHighlight all proper nouns by surrounding them with ** (e.g., Google).\\n\\n\\nIf a sentence is longer than 20 words, split it into two sentences.\\n\\n\\nMerge any two consecutive sentences that are both under 8 words.\\n\\n\\nLeave the final sentence unchanged, even if other rules apply.\\n\\n\\nKeep only the first and last paragraph; delete all others.\\n\\n\\nAdd a summary line at the beginning: ‚Äú Edited for clarity and compliance.‚Äù\\n\\n\\nReturn the final output as plain text with line breaks between paragraphs.\\n\\n\\nIn 2023, researchers at MIT developed an AI-driven tool to streamline logistics in urban environments like New York and Tokyo. The tool uses IoT sensors to collect data from thousands of delivery trucks, ensuring real-time visibility into routes. \\nAlthough the technology was in development for over two years, it gained commercial traction only after successful trials in Berlin. It was said that the system was designed to be scalable and efficient. However, analysts at Stanford warned of data privacy concerns. \\nThe software was later integrated with ERP systems by a team based in Lahore. This allowed seamless automation across multiple distribution hubs. One key feature involved predictive maintenance, powered by machine learning and natural language processing models. \\nThese models were trained on over 250,000 historical delivery records, offering unparalleled insights. Meanwhile, the company‚Äôs R&D division in Toronto continued improving model accuracy. Despite setbacks, the project demonstrated remarkable efficiency gains. The final release was announced at the Smart Cities Expo in Dubai.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIUJGQ6E16vP",
        "outputId": "2f3f1eb2-733e-4690-f224-1485c5695768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"\"]"
      ],
      "metadata": {
        "id": "hRtRspsYuvtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUkpyDwrIBc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalauet t on data sets"
      ],
      "metadata": {
        "id": "1ui7pq4N9OLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = anthropic.Anthropic()\n",
        "results = score(prompts, completions, model_ids)"
      ],
      "metadata": {
        "id": "hFIUrLOqBLOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEbZKLFnYXUV",
        "outputId": "ee9508c5-38b4-495b-8522-0e168ebc6d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Gemini': 0.0, 'Mistral': 0.0, 'OpenAi': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntheDiFXBY0J",
        "outputId": "12d1382c-5cb1-4fab-dea6-096878ae07fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Gemini': 0.4642857142857143, 'Mistral': 0.5357142857142857, 'OpenAi': 0.5357142857142857}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HApSFlTRBa-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6708040b",
        "outputId": "89c495aa-53a8-44fe-db66-b7277355f2e2"
      },
      "source": [
        "%pip install anthropic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.60.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n"
          ]
        }
      ]
    }
  ]
}