{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68JipEvJ3d1X"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltZLwFQ7ipKA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xE50QtTKipPn"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\" Prompt:  Instruction-Following\n",
        "You are an advanced text processing agent. Follow each of the 15 instructions below exactly and in order. Apply them to the provided paragraph. Be precise, strict with conditions, and make no omissions or assumptions beyond the rules.\n",
        "\n",
        "🔧 Instructions:\n",
        "Replace all acronyms with their full forms (e.g., AI → Artificial Intelligence).\n",
        "\n",
        "\n",
        "Remove any sentence that contains more than two numerical digits.\n",
        "\n",
        "\n",
        "Capitalize the first word of every sentence.\n",
        "\n",
        "\n",
        "Do not alter the third sentence in the original paragraph.\n",
        "\n",
        "\n",
        "Change passive voice to active voice in even-numbered sentences only.\n",
        "\n",
        "\n",
        "Remove any sentence that starts with \"However\" or \"Although.\"\n",
        "\n",
        "\n",
        "If a sentence includes a city name, replace it with \"[REDACTED]\".\n",
        "\n",
        "\n",
        "In any sentence containing the word “data,” add the word “sensitive” before “data.”\n",
        "\n",
        "\n",
        "Highlight all proper nouns by surrounding them with ** (e.g., Google).\n",
        "\n",
        "\n",
        "If a sentence is longer than 20 words, split it into two sentences.\n",
        "\n",
        "\n",
        "Merge any two consecutive sentences that are both under 8 words.\n",
        "\n",
        "\n",
        "Leave the final sentence unchanged, even if other rules apply.\n",
        "\n",
        "\n",
        "Keep only the first and last paragraph; delete all others.\n",
        "\n",
        "\n",
        "Add a summary line at the beginning: “ Edited for clarity and compliance.”\n",
        "\n",
        "\n",
        "Return the final output as plain text with line breaks between paragraphs.\n",
        "\n",
        "\n",
        "In 2023, researchers at MIT developed an AI-driven tool to streamline logistics in urban environments like New York and Tokyo. The tool uses IoT sensors to collect data from thousands of delivery trucks, ensuring real-time visibility into routes.\n",
        "Although the technology was in development for over two years, it gained commercial traction only after successful trials in Berlin. It was said that the system was designed to be scalable and efficient. However, analysts at Stanford warned of data privacy concerns.\n",
        "The software was later integrated with ERP systems by a team based in Lahore. This allowed seamless automation across multiple distribution hubs. One key feature involved predictive maintenance, powered by machine learning and natural language processing models.\n",
        "These models were trained on over 250,000 historical delivery records, offering unparalleled insights. Meanwhile, the company’s R&D division in Toronto continued improving model accuracy. Despite setbacks, the project demonstrated remarkable efficiency gains. The final release was announced at the Smart Cities Expo in Dubai.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FRU_c7lal1bk"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z26zj-mllYZ"
      },
      "source": [
        "Make the data set\n",
        "laod the phi model\n",
        "define the functions\n",
        "one for judjde the outputs\n",
        "one in which this function will be called\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "e7C6j-2ptGqX"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict\n",
        "\n",
        "import openai\n",
        "\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODQO2mV6r6tf"
      },
      "outputs": [],
      "source": [
        "# keys\n",
        "openai.api_key = \"Yor api key\"  # ⚠️ Replace with your actual key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "TJVSBFTHA5s5"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "9s7JxtFFrp2j"
      },
      "outputs": [],
      "source": [
        "def judge_instructions_compliance(instructions: List[str], original_paragraph: str, completion: str) -> int:\n",
        "    \"\"\"\n",
        "    Calls OpenAI GPT model to judge how many of the instructions were followed exactly.\n",
        "\n",
        "    Args:\n",
        "        instructions: List of N instructions (ideally 5 per call)\n",
        "        original_paragraph: The raw input paragraph\n",
        "        completion: The model's edited output\n",
        "\n",
        "    Returns:\n",
        "        Integer count of how many instructions (0-N) were followed exactly\n",
        "    \"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are an expert evaluator of instruction-following in text editing tasks. \"\n",
        "        \"You will be given a set of editing instructions, the original paragraph, and a modified paragraph. \"\n",
        "        \"You must return ONLY the number of instructions that were followed exactly. \"\n",
        "        \"Do not explain or justify. Just return a single number (0 to N).\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Instructions:\n",
        "{chr(10).join(f\"{i+1}. {instr}\" for i, instr in enumerate(instructions))}\n",
        "\n",
        "Original Paragraph:\n",
        "{original_paragraph}\n",
        "\n",
        "Edited Output:\n",
        "{completion}\n",
        "\n",
        "How many of the above {len(instructions)} instructions were followed exactly?\n",
        "Return just the number, nothing else.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",  # or \"gpt-3.5-turbo\", or \"o3-mini\" if you prefer\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        reply = response.choices[0].message.content.strip()\n",
        "        match = re.search(r'\\d+', reply)\n",
        "        if match:\n",
        "            value = int(match.group(0))\n",
        "            return max(0, min(value, len(instructions)))\n",
        "        else:\n",
        "            print(f\"Unexpected format in OpenAI response: {reply}\")\n",
        "            return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in OpenAI call: {e}\")\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "s15GGzn3oHn6"
      },
      "outputs": [],
      "source": [
        "# helper function to extract the parapgah and  instructions\n",
        "def extract_instructions_and_paragraph(prompt: str) -> tuple[list[str], str]:\n",
        "    start_marker = \"Instructions:\"\n",
        "    end_marker = \"Return the final output as plain text with line breaks between paragraphs.\"\n",
        "\n",
        "    if start_marker in prompt and end_marker in prompt:\n",
        "        # Find start and end positions\n",
        "        start_index = prompt.index(start_marker) + len(start_marker)\n",
        "        end_index = prompt.index(end_marker) + len(end_marker)\n",
        "\n",
        "        # Extract instruction block (excluding the \"Instructions:\" line itself)\n",
        "        instructions_block = prompt[start_index:prompt.index(end_marker)].strip()\n",
        "\n",
        "        # Split instructions into list by lines and remove empty ones\n",
        "        instructions_list = [line.strip() for line in instructions_block.splitlines() if line.strip()]\n",
        "\n",
        "        # Extract paragraph after end marker\n",
        "        paragraph = prompt[end_index:].strip()\n",
        "\n",
        "        if not instructions_list:\n",
        "            raise ValueError(\"No instructions found between markers.\")\n",
        "        if not paragraph:\n",
        "            raise ValueError(\"No paragraph found after the instructions block.\")\n",
        "\n",
        "        return instructions_list, paragraph\n",
        "\n",
        "    raise ValueError(\"Start or end marker not found in prompt.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "MMKd5xqhoFRN"
      },
      "outputs": [],
      "source": [
        "# Helper function to split the instructions into different\n",
        "def chunk_instructions(instructions: List[str], n_parts: int = 2) -> List[List[str]]:\n",
        "    total = len(instructions)\n",
        "    base_size = total // n_parts\n",
        "    remainder = total % n_parts\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    for i in range(n_parts):\n",
        "        # First 'remainder' chunks get one extra item\n",
        "        chunk_size = base_size + (1 if i < remainder else 0)\n",
        "        end = start + chunk_size\n",
        "        chunks.append(instructions[start:end])\n",
        "        start = end\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "dZ2Ptgbtn8dQ"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "def score(prompts: List[str], completions: List[str], models: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Scores prompt-completion pairs for compliance with instruction sets.\n",
        "\n",
        "    Args:\n",
        "        prompts: List of full prompts (including instructions + paragraph)\n",
        "        completions: List of completions corresponding to the prompts\n",
        "        models: List of model identifiers for each completion\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of model_id → average compliance score (0.0 to 1.0)\n",
        "    \"\"\"\n",
        "    assert len(prompts) == len(completions) == len(models), \"Input lists must be equal length\"\n",
        "\n",
        "    model_scores = defaultdict(list)\n",
        "\n",
        "    # === Extract instructions and paragraph from the first prompt ===\n",
        "    full_instructions, Shared_paragraph = extract_instructions_and_paragraph(prompts[0])\n",
        "    instruction_chunks = chunk_instructions(full_instructions, n_parts=2)  # Or adjust n_parts as needed\n",
        "\n",
        "    for prompt, completion, model_id in zip(prompts, completions, models):\n",
        "\n",
        "        total_followed = 0\n",
        "        for chunk in instruction_chunks:\n",
        "            followed = judge_instructions_compliance(chunk, Shared_paragraph, completion)\n",
        "            total_followed += followed\n",
        "\n",
        "        compliance_score = total_followed / len(full_instructions)\n",
        "        model_scores[model_id].append(compliance_score)\n",
        "\n",
        "    # === Average the compliance scores per model ===\n",
        "    avg_scores = {\n",
        "        model_id: sum(scores) / len(scores)\n",
        "        for model_id, scores in model_scores.items()\n",
        "    }\n",
        "\n",
        "    return avg_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ucBNPabklbwF"
      },
      "outputs": [],
      "source": [
        "def chunk_instructions(instructions: List[str], n_parts: int = 2) -> List[List[str]]:\n",
        "    total = len(instructions)\n",
        "    base_size = total // n_parts\n",
        "    remainder = total % n_parts\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    for i in range(n_parts):\n",
        "        # First 'remainder' chunks get one extra item\n",
        "        chunk_size = base_size + (1 if i < remainder else 0)\n",
        "        end = start + chunk_size\n",
        "        chunks.append(instructions[start:end])\n",
        "        start = end\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sSvlsBHwifRW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9WPbNlAxhfq"
      },
      "source": [
        "Making the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "F4w6r4TD0dD3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import List\n",
        "def read_prompt_as_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "\n",
        "     return f.read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "vC-0eLDIhUu6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_completions(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    completions = re.findall(r\"Completion \\d+:\\s*(.*?)\\s*(?=Completion \\d+:|$)\", text, re.DOTALL)\n",
        "    return [c.strip() for c in completions]\n",
        "\n",
        "def load_models(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        models = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    return models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "F_9QpyjEuvoQ"
      },
      "outputs": [],
      "source": [
        "prompt = read_prompt_as_text(\"/content/Prompts.txt\")\n",
        "completions = load_completions(\"/content/Completions.txt\")\n",
        "model_ids = load_models(\"/content/Models.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "T-cFwBXxuvrB"
      },
      "outputs": [],
      "source": [
        "prompts = [prompt] * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "3WIF-UM-2Fpb",
        "outputId": "8b346952-427d-4dd0-ca36-7ab5af15b471"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prompt:  Instruction-Following \\nYou are an advanced text processing agent. Follow each of the 15 instructions below exactly and in order. Apply them to the provided paragraph. Be precise, strict with conditions, and make no omissions or assumptions beyond the rules.\\n\\n🔧 Instructions:\\nReplace all acronyms with their full forms (e.g., AI → Artificial Intelligence).\\n\\n\\nRemove any sentence that contains more than two numerical digits.\\n\\n\\nCapitalize the first word of every sentence.\\n\\n\\nDo not alter the third sentence in the original paragraph.\\n\\n\\nChange passive voice to active voice in even-numbered sentences only.\\n\\n\\nRemove any sentence that starts with \"However\" or \"Although.\"\\n\\n\\nIf a sentence includes a city name, replace it with \"[REDACTED]\".\\n\\n\\nIn any sentence containing the word “data,” add the word “sensitive” before “data.”\\n\\n\\nHighlight all proper nouns by surrounding them with ** (e.g., Google).\\n\\n\\nIf a sentence is longer than 20 words, split it into two sentences.\\n\\n\\nMerge any two consecutive sentences that are both under 8 words.\\n\\n\\nLeave the final sentence unchanged, even if other rules apply.\\n\\n\\nKeep only the first and last paragraph; delete all others.\\n\\n\\nAdd a summary line at the beginning: “ Edited for clarity and compliance.”\\n\\n\\nReturn the final output as plain text with line breaks between paragraphs.\\n\\n\\nIn 2023, researchers at MIT developed an AI-driven tool to streamline logistics in urban environments like New York and Tokyo. The tool uses IoT sensors to collect data from thousands of delivery trucks, ensuring real-time visibility into routes. \\nAlthough the technology was in development for over two years, it gained commercial traction only after successful trials in Berlin. It was said that the system was designed to be scalable and efficient. However, analysts at Stanford warned of data privacy concerns. \\nThe software was later integrated with ERP systems by a team based in Lahore. This allowed seamless automation across multiple distribution hubs. One key feature involved predictive maintenance, powered by machine learning and natural language processing models. \\nThese models were trained on over 250,000 historical delivery records, offering unparalleled insights. Meanwhile, the company’s R&D division in Toronto continued improving model accuracy. Despite setbacks, the project demonstrated remarkable efficiency gains. The final release was announced at the Smart Cities Expo in Dubai.\\n\\n'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIUJGQ6E16vP",
        "outputId": "2f3f1eb2-733e-4690-f224-1485c5695768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P\n"
          ]
        }
      ],
      "source": [
        "print(prompt[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRtRspsYuvtt"
      },
      "outputs": [],
      "source": [
        "prompts = [\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUkpyDwrIBc0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ui7pq4N9OLm"
      },
      "source": [
        "Evalauet t on data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "hFIUrLOqBLOM"
      },
      "outputs": [],
      "source": [
        "results = score(prompts, completions, model_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntheDiFXBY0J",
        "outputId": "45d4024e-9761-432a-da1a-d33292aeae82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Gemini': 0.5, 'Mistral': 0.5, 'OpenAi': 0.6428571428571429}\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HApSFlTRBa-b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
